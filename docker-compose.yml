services:
  app:
    build:
      context: .
      dockerfile: src/api/Dockerfile
    depends_on:
      ollama:
        condition: service_healthy
      qdrant:
        condition: service_started
    environment:
      - SERVICE_PROVIDER=ollama
      - LLM_ENDPOINT=http://ollama:11434
      - LLM_MODEL=llama3.1:8b
      - EMBEDDING_MODEL=nomic-embed-text
      - QDRANT_HOST=qdrant
      - QDRANT_USE_HTTPS=false
      - DATA_STORAGE_CONNECTION_STRING=/home/app/rag.db
    ports:
      - "8080:8080"
    volumes:
      - rag-data:/home/app/
    networks:
      - ai-net

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
      - ./ollama-init.sh:/ollama-init.sh
    entrypoint: ["/bin/bash", "/ollama-init.sh"]
    environment:
      - EMBEDDING_MODEL=nomic-embed-text
      - SUMMARIZING_MODEL=llama3.1:8b
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - ai-net

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      - ai-net

volumes:
  ollama-data:
  qdrant-data:
  rag-data:

networks:
  ai-net:
    driver: bridge